{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " # !pip install --upgrade pip\n",
    "# !pip install pytorch\n",
    "# !pip install transformers\n",
    "# ! sudo apt install tesseract-ocr\n",
    "# ! pip install pytesseract\\n\",\n",
    "# ! pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 12:04:56.181133: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-05 12:04:56.181161: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer #tokanization and removel of punctuation \\n\",\n",
    "\n",
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Layer#, InputSpec\n",
    "from tensorflow.keras import initializers, regularizers, constraints\n",
    "#from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Input, Dense, GRU, Bidirectional, TimeDistributed, Dropout\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "#from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Admin Note', 'Clinical History And Summary', 'Consult Note', 'Cover Page', 'Imaging Note', 'Insurance Authorization', 'Intake Forms', 'Lab Test', 'Other', 'Patient Profile', 'Prescriptions', 'Referral Letter', 'Requisition Form']\n"
     ]
    }
   ],
   "source": [
    "#classes\n",
    "txt_path='/media/umar_visionx/Backup Plus/Active/Faizan/doc_classifier_classes.txt'\n",
    "with open(txt_path,'r') as file:\n",
    "    classes=file.read().split('\\n')\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['North_Texas_Corp_LoneStar_2020-11-24_0012169206217_2020-11-24-23.36.36_OK_HSA0.png.ocr.json',\n",
       " 'North_Texas_Amarillo_2020-11-24_0018479841164_2020-11-24-21.45.11_OK_7NV1.png.ocr.json',\n",
       " '003B35A1_0.png.ocr.json',\n",
       " 'Mid_Florida_Kissimmee_West_2020-11-25_0016173936905_2020-11-25-10.12.32_OK_BMS0.pkl',\n",
       " 'North_Texas_Amarillo_2020-11-25_0014693513968_2020-11-25-14.40.47_OK_A7T1.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr_train='/media/umar_visionx/Backup Plus/Active/Faizan/data_copy/ocr'\n",
    "ocr_test='/media/umar_visionx/Backup Plus/Active/Faizan/data_copy/test-set/ocr_textract'\n",
    "os.listdir(ocr_train)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making folders and saving the text files (with extracted text from image) in related folders\n",
    "def extract_text(source_path,dest_path,ocr_path):\n",
    "        #first making folders\n",
    "        try:\n",
    "            os.makedirs(dest_path)\n",
    "            for ent in classes:\n",
    "                folder_path=os.path.join(dest_path,ent)\n",
    "                os.makedirs(folder_path)\n",
    "            print(\"Folder making process completed\")\n",
    "        except:\n",
    "            pass\n",
    "        for folder in os.listdir(source_path):\n",
    "            folder_path=os.path.join(source_path,folder)\n",
    "            for files in os.listdir(folder_path):\n",
    "                    ocr_file=os.path.splitext(files)[0] + \".png.ocr.json\"#making the name of ocr file to get access from ocr folder\n",
    "                    ocr_f_path=os.path.join(ocr_path,ocr_file)#making directory of ocr_file in ocr folder\n",
    "                    try:\n",
    "                        with open(ocr_f_path,'r') as f:\n",
    "                            output=json.load(f)\n",
    "                        \n",
    "                        if isinstance(output,dict):#if type of 'output' is dictionary\n",
    "                            words=[]\n",
    "                            for block in output['Blocks']:\n",
    "                                if block['BlockType']=='WORD':\n",
    "                                    words.append(block[\"Text\"])\n",
    "                            para= ' '.join(words)\n",
    "                            \n",
    "                        elif isinstance(output,list):#if type of 'output' is list\n",
    "                            output = output[0]\n",
    "                            para = \" \".join([i[\"Text\"] for i in output[\"Blocks\"] if i[\"BlockType\"] == \"LINE\"])\n",
    "                        \n",
    "                        elif isinstance(output,tuple):\n",
    "                            output = output[0]\n",
    "                            para = \" \".join([i[\"Text\"] for i in output[\"Blocks\"] if i[\"BlockType\"] == \"LINE\"])\n",
    "                        \n",
    "                        #making directory to save the files with same file and folder name\n",
    "                        txt_file=os.path.splitext(files)[0] + \".txt\" #making same name of file as image\n",
    "                        txt_path=os.path.join(dest_path,os.path.join(folder,txt_file))\n",
    "                        #writing and saving file\n",
    "                        with open(txt_path, \"w\") as file:\n",
    "                            file.write(para)\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "        print(\"All text files are created successfully\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting text from images and creating text files \\n\",\n",
    "train_image=\"/media/umar_visionx/Backup Plus/Active/Faizan/image_data\"#image data source path\n",
    "test_image=\"/media/umar_visionx/Backup Plus/Active/Faizan/test_images\"#test image data source path\n",
    "train_text=\"/media/umar_visionx/Backup Plus/Active/Faizan/textrect_dataset\"#extracted text files destinatio path for image data\n",
    "test_text=\"/media/umar_visionx/Backup Plus/Active/Faizan/textrect_test_dataset\"#extracted text files destination path from test image data\n",
    "# extract_text(train_image,train_text,ocr_train)\n",
    "# extract_text(test_image,test_text,ocr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18678\n"
     ]
    }
   ],
   "source": [
    "#total number of json files in ocr folder\n",
    "lst=[]\n",
    "for files in os.listdir(ocr_train):\n",
    "    if files.endswith('.json'):\n",
    "        lst.append(files)\n",
    "print(len(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11660\n",
      "1810\n",
      "11660\n",
      "1670\n"
     ]
    }
   ],
   "source": [
    "#getting the sum of files in each folder\\n\",\n",
    "def sum_it(path):\n",
    "    total=[]\n",
    "    for folder in os.listdir(path):\n",
    "        folder_path=os.path.join(path,folder)\n",
    "        total.append(len(os.listdir(folder_path)))\n",
    "    print(sum(total))\n",
    "sum_it(train_image)\n",
    "sum_it(test_image)\n",
    "sum_it(train_text)\n",
    "sum_it(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing special character and numbers\n",
    "def rem_sp_char(words):\n",
    "    pattern = r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]'  # defined pattern to keep\n",
    "    words=re.sub(pattern, '', words)\n",
    "    return words\n",
    "\n",
    "#tokanizing and removing punctuations\n",
    "def remove_punct(words):\n",
    "  tokenizer = RegexpTokenizer(r'\\w+')\n",
    "  tokens=tokenizer.tokenize(words)\n",
    "  return tokens\n",
    "\n",
    "#lemmitization\n",
    "def lemmitizar(words):\n",
    "  lemmatized_words=[]\n",
    "  l = WordNetLemmatizer()\n",
    "  for word in words:\n",
    "      token = l.lemmatize(word)\n",
    "      lemmatized_words.append(token)\n",
    "  return lemmatized_words\n",
    "\n",
    "#removing stop-words\n",
    "def remove_stopwords(words):\n",
    "  filter_words = []\n",
    "  Stopwords = stopwords.words('english')\n",
    "  for word in words:\n",
    "      if word not in Stopwords:\n",
    "          filter_words.append(word)\n",
    "  return filter_words\n",
    "\n",
    "#converting to lowercase\n",
    "def lower_case(words):\n",
    "  lower_words=[]\n",
    "  for word in words:\n",
    "    lower_words.append(word.lower())\n",
    "  return lower_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Admin Note': 0,\n",
       " 'Clinical History And Summary': 1,\n",
       " 'Consult Note': 2,\n",
       " 'Cover Page': 3,\n",
       " 'Imaging Note': 4,\n",
       " 'Insurance Authorization': 5,\n",
       " 'Intake Forms': 6,\n",
       " 'Lab Test': 7,\n",
       " 'Other': 8,\n",
       " 'Patient Profile': 9,\n",
       " 'Prescriptions': 10,\n",
       " 'Referral Letter': 11,\n",
       " 'Requisition Form': 12}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label encoding\n",
    "labl=[]\n",
    "for folder in os.listdir(train_text):\n",
    "  labl.append(folder)#making the list of folder names which are labels\n",
    "\n",
    "\n",
    "#encoding the labels from the list\n",
    "label_index={}\n",
    "for index,label in enumerate(labl):\n",
    "  label_index[label]=index\n",
    "\n",
    "label_index#label to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dictionaries and lists of text and labels\n",
    "def preprocessed_df(data_path):\n",
    "        #txt_file_path=[]\n",
    "        labels=[]\n",
    "        text=[]\n",
    "        encoded_labels=[]\n",
    "        for clss in os.listdir(data_path):\n",
    "            clss_path=os.path.join(data_path,clss)\n",
    "            for txt_file in os.listdir(clss_path):\n",
    "                file_path=os.path.join(clss_path,txt_file)\n",
    "                #reading text file\n",
    "                with open(file_path, \"r\") as file:\n",
    "                    para = file.read().rstrip('\\n')#rstrip method removes trailing character based on string argument passed\n",
    "                #apply preprocessing functions on para\n",
    "                words = rem_sp_char(para) #removing special character and numbers\n",
    "                tokens = remove_punct(words) #removing punctuations and tokanization\n",
    "                tokens = lemmitizar(tokens) #lemmitization\n",
    "                tokens = remove_stopwords(tokens) ##removing stop-words\n",
    "                tokens = lower_case(tokens) #converting to lowercase\n",
    "    \n",
    "                #joining words with space and removing single tetter tokens\n",
    "                parag=' '.join(tokens)\n",
    "\n",
    "                #inseting data into lists\n",
    "                text.append(parag)\n",
    "                #text_file_path.append(file_path)\n",
    "                labels.append(clss)\n",
    "    #label encoding\n",
    "        for ent in labels:\n",
    "            encoded_labels.append(label_index[ent])\n",
    "        \n",
    "    \n",
    "    \n",
    "        df=pd.DataFrame()\n",
    "        df['text']=text\n",
    "        df['labels']=encoded_labels\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7 29 2021 10 42 alberta health services rrduse...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7 30 2021 09 34 alberta health services rrduse...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7 29 2021 11 03 alberta health services rrduse...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8 4 2021 08 25 alber ta health services rrduse...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ahs 8 4 2021 7 23 05 am page 2 002 fax server ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0  7 29 2021 10 42 alberta health services rrduse...       0\n",
       "1  7 30 2021 09 34 alberta health services rrduse...       0\n",
       "2  7 29 2021 11 03 alberta health services rrduse...       0\n",
       "3  8 4 2021 08 25 alber ta health services rrduse...       0\n",
       "4  ahs 8 4 2021 7 23 05 am page 2 002 fax server ...       0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=preprocessed_df(train_text)\n",
    "df_test=preprocessed_df(test_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11660\n",
      "1670\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#BERT base model\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased',output_hidden_states = True,)#model returns all hidden-states.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "train_dataset = Dataset.from_pandas(df)\n",
    "#val_dataset = Dataset.from_pandas(df_val)\n",
    "test_dataset = Dataset.from_pandas(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_example(sample,max_seq_length=512):\n",
    "    words=sample['text']\n",
    "    label=sample['labels']\n",
    "    #splitting all words of sentence in to into tokens\n",
    "    tokenized_text = tokenizer.tokenize(words)\n",
    "    # Truncation of token_boxes\n",
    "    special_tokens_count = 2 \n",
    "    if len(tokenized_text) > max_seq_length - special_tokens_count:\n",
    "      tokenized_text = tokenized_text[: (max_seq_length - special_tokens_count)]#to make place available for cls and sep tokens\n",
    "    # Adding CLS and SEP tokens\n",
    "    input_sequence = [\"[CLS]\"] + tokenized_text + [\"[SEP]\"]\n",
    "    # Map the tokens to their vocabulary indeces\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "    #padding length\n",
    "    padding_length = max_seq_length - len(input_sequence)\n",
    "    indexed_tokens += [0] * padding_length#zero padding to maximum length\n",
    "    #as we are giving as a single sentence so mark each token as belonging to sentence 1\n",
    "    segments_ids = [1] * max_seq_length\n",
    "    pad_masks = [1] * len(input_sequence) + [0] * padding_length\n",
    "\n",
    "\n",
    "    assert len(indexed_tokens) == max_seq_length\n",
    "    assert len(segments_ids) ==max_seq_length\n",
    "    assert len(pad_masks) == max_seq_length\n",
    "\n",
    "    #converting into pytorch tensors\n",
    "    tokens_tensor = torch.tensor(indexed_tokens)\n",
    "    segments_tensors = torch.tensor(segments_ids)\n",
    "    pad_mask_tensors=torch.tensor(pad_masks)\n",
    "    label_tensors=torch.tensor(label)\n",
    "    \n",
    "  \n",
    "    tok_tensors.append(tokens_tensor)\n",
    "    seg_tensors.append(segments_tensors)\n",
    "    lab_tensors.append(label_tensors)\n",
    "    pad_msk_tensors.append(pad_mask_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_df(dataset):\n",
    "    global tok_tensors,seg_tensors,lab_tensors,pad_msk_tensors\n",
    "\n",
    "    tok_tensors=[]\n",
    "    seg_tensors=[]\n",
    "    lab_tensors=[]\n",
    "    pad_msk_tensors=[]\n",
    "    dataset.map(encode_example)\n",
    "    # df=pd.DataFrame()\n",
    "    # df['token_tensors']=tok_tensors\n",
    "    # df['segment_tensor']=seg_tensors\n",
    "    # df['labels']=lab_tensors\n",
    "    return tok_tensors,seg_tensors,lab_tensors,pad_msk_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3011d6aa3d45acbc9c6365def75df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11660 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7eaeb70ce5e42779ebaf3f2ecabc1fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1670 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_token_tensor,tr_segment_tensors,tr_label_tensors,tr_pad_msk_tensors=iter_df(train_dataset)\n",
    "ts_token_tensor,ts_segment_tensors,ts_label_tensorsts,ts_pad_msk_tensors=iter_df(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset\n",
    "class PhelixDataset(Dataset):\n",
    "    def __init__(self, token_tens,label_tens,seg_tens,pd_msk_tens):\n",
    "        #super().__init__()\n",
    "        self.token_tens = token_tens\n",
    "        self.seg_tens=seg_tens\n",
    "        self.label_tens=label_tens\n",
    "        self.pd_msk_tens=pd_msk_tens\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_tens)\n",
    "    \n",
    "    def __getitem__(self, index):       \n",
    "        tokens_id = self.token_tens[index]\n",
    "        segment_id = self.seg_tens[index]\n",
    "        label=self.label_tens[index]\n",
    "        pad_mask=self.pd_msk_tens[index]\n",
    "\n",
    "        return tokens_id,label,segment_id,pad_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  101,  1022,  1023, 25682,  1023,  5354,  7610,  2013,  7987,  3593,\n",
      "         26580,  2966,  2000,  4601,  2575,  2620, 12740, 21619,  2692,  2575,\n",
      "          3931, 25604,  1997,  4002,  2475,  7987,  3593, 26580,  2966,  3328,\n",
      "          2378,  9349, 17222,  2692, 13745,  3927,  3131,  8148, 18603,  2006,\n",
      "          2710, 23290,  2860,  2475,  2015,  2620,  6904,  2595,  3104,  7123,\n",
      "          2000,  3010,  4315, 18900,  6779,  2803,  3042,  4601,  2575, 18827,\n",
      "         18139, 24434,  2581,  6904,  2595,  4601,  2575,  2620, 12740, 21619,\n",
      "          2692,  2575,  3058, 25682,  4887,  2290,  2692,  2683,  2013,  2852,\n",
      "          2745,  8825,  8915,  4221, 20850,  4887,  2213,  3042,  4601, 21084,\n",
      "          2683,  2683, 28154, 21084,  6904,  2595,  4601,  2575,  4749, 16068,\n",
      "          2620, 23499,  2193,  3931,  2164,  3104,  1016, 18777,  2023,  4807,\n",
      "          3832,  3265,  5145,  8280,  5500, 15826, 21362,  3087,  2842,  1996,\n",
      "          6254,  4807,  2089,  5383,  3167, 18777, 21598,  2592,  2089,  3395,\n",
      "          4071,  2592,  3860,  9394,  2552,  2740,  2592,  2552,  6094,  2065,\n",
      "          2363,  4807,  7561,  3531,  2025,  8757,  1057,  3202,  2709,  2434,\n",
      "          6726,  1057,  4067,  6792,  5375,  2128,  7842, 25205, 11113, 19848,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), tensor([3]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])]\n"
     ]
    }
   ],
   "source": [
    "batch_size=1\n",
    "train_data = PhelixDataset(tr_token_tensor,tr_label_tensors,tr_segment_tensors,tr_pad_msk_tensors)\n",
    "test_data = PhelixDataset(ts_token_tensor,ts_label_tensorsts,ts_segment_tensors,ts_pad_msk_tensors)\n",
    "train_dataloader = DataLoader(train_data, batch_size = batch_size,shuffle=True,num_workers=3,pin_memory=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size = batch_size,shuffle=False,num_workers=3,pin_memory=True)\n",
    "sample = next(iter(train_dataloader))\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n",
      "torch.Size([1])\n",
      "torch.Size([1, 512])\n",
      "torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "for token, label,seg,pad_mask in train_dataloader:\n",
    "    print(token.shape)\n",
    "    print(label.shape)\n",
    "    print(seg.shape)\n",
    "    print(pad_mask.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_data='/media/umar_visionx/Backup Plus/Active/Faizan/textrect_saved_vectors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def embed(data_loader,train):\n",
    "  #creating word embeddings\n",
    "  model.eval()\n",
    "  # token_labels_list=[]\n",
    "  # concat_token_vect=[]#define list to append concatinated token vectors\n",
    "  # doc_vectors_list=[]\n",
    "  # doc_label_list=[]\n",
    "  #to save data as arrays \n",
    "  token_labels_list_arr=[]\n",
    "  concat_token_vect_arr=[]\n",
    "  # doc_vectors_list_arr=[]\n",
    "  # doc_label_list_arr=[]\n",
    "\n",
    "\n",
    "\n",
    "  if train==True:\n",
    "            ft=open(os.path.join(saved_data,'train_feat.pickle'), 'ab')\n",
    "            lb=open(os.path.join(saved_data,'train_label.pickle'), 'ab')\n",
    "  else:\n",
    "            ft=open(os.path.join(saved_data,'test_feat.pickle'), 'ab')\n",
    "            lb=open(os.path.join(saved_data,'test_label.pickle'), 'ab')\n",
    "  for tokens,label,seg_id,_ in tqdm(data_loader):\n",
    "\n",
    "      #moving to device\n",
    "      label=int(label)\n",
    "      tokens=tokens.to(device)\n",
    "      seg_id=seg_id.to(device)\n",
    "      with torch.no_grad():\n",
    "        output = model(tokens,seg_id)\n",
    "      #we set output_hidden_state=True in our pre trained model so, we will get the hidden states from all 13 layers at third positiob\n",
    "      hidden_states = output[2]\n",
    "      #For futher info please check https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/\n",
    "      # Concatenating tensors for all layers and creating new dim with the help of stack\n",
    "      token_embed = torch.stack(hidden_states, dim=0)#token embeddings(torch.Size([13, 1, 512, 768]))\n",
    "      token_embed = torch.squeeze(token_embed, dim=1)#removing batch dimension(torch.Size([13, 512, 768]))\n",
    "      token_embed = token_embed.permute(1,0,2)# swapping dimensions(torch.Size([512, 13, 768]))\n",
    "      #iterating for each token in whole document/sentense\n",
    "      to_append_vect=[]\n",
    "      to_append_vect_arr=[]\n",
    "      #to_append_label=[]\n",
    "      for token in token_embed:\n",
    "          #token vector of size 13*768 where 13 are number of layers while we want to get only last 4 layers i.e 4*768\n",
    "          #after concatination last four layers vector dimensions will be 4*768=3,072(singlre word vector length i.e per token)\n",
    "          #concatinating vectors\n",
    "          add1 = torch.add(token[-1], token[-2])\n",
    "          add2=torch.add(token[-3], token[-4])\n",
    "          full_vector=torch.add(add1,add2)\n",
    "          #concatcat_vector = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "          # concat_token_vect.append(full_vector)\n",
    "          #we have append 512 vectors of size 768 for each document\n",
    "          # token_labels_list.append(label)\n",
    "          token_labels_list_arr.append(label)\n",
    "          concat_token_vect_arr.append(full_vector.cpu().numpy())\n",
    "\n",
    "          to_append_vect_arr.append(full_vector.cpu().numpy())\n",
    "          to_append_vect.append(full_vector)\n",
    "          #to_append_label.append(label)\n",
    "      # print(len(to_append_vect_arr))\n",
    "      # print(len(to_append_vect))\n",
    "\n",
    "\n",
    "      # doc_vectors_list.append(to_append_vect)\n",
    "      # doc_label_list.append(label)\n",
    "      # doc_vectors_list_arr.append(to_append_vect_arr)\n",
    "      # doc_label_list_arr.append(label)\n",
    "\n",
    "      # with open(os.path.join(saved_data,\"train_features.pickle\"),'ab') as f:\n",
    "      #   pickle.dump(to_append_vect_arr,f)\n",
    "      # with open(os.path.join(saved_data,\"train_labels.pickle\"),'ab') as f:\n",
    "      #   pickle.dump(label,f)\n",
    "      pickle.dump(to_append_vect_arr,ft)\n",
    "      pickle.dump(label,lb)\n",
    "  ft.close()\n",
    "  lb.close()\n",
    "\n",
    "  #return doc_vectors_list_arr,doc_label_list_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11660/11660 [11:25<00:00, 17.00it/s]\n",
      "100%|██████████| 1670/1670 [01:35<00:00, 17.56it/s]\n"
     ]
    }
   ],
   "source": [
    "#Generating Embeddings\n",
    "\n",
    "embed(train_dataloader,True)\n",
    "embed(test_dataloader,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#loading data from pickle file\n",
    "def ext_data(filepath):\n",
    "\n",
    "    data = []\n",
    "    with open(filepath, 'rb') as fr:\n",
    "        try:\n",
    "            while True:\n",
    "                data.append(pickle.load(fr))\n",
    "        except EOFError:\n",
    "            pass\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "train_feat_path='/media/umar_visionx/Backup Plus/Active/Faizan/textrect_saved_vectors/train_feat.pickle'\n",
    "train_label_path='/media/umar_visionx/Backup Plus/Active/Faizan/textrect_saved_vectors/train_label.pickle'\n",
    "test_feat_path='/media/umar_visionx/Backup Plus/Active/Faizan/textrect_saved_vectors/test_feat.pickle'\n",
    "test_label_path='/media/umar_visionx/Backup Plus/Active/Faizan/textrect_saved_vectors/test_label.pickle'\n",
    "doc_vectors_list_arr=ext_data(train_feat_path)\n",
    "doc_label_list_arr=ext_data(train_label_path)\n",
    "test_vector_list_arr=ext_data(test_feat_path)\n",
    "test_label_list_arr=ext_data(test_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del doc_vectors_list_arr\n",
    "# del doc_label_list_arr\n",
    "# del test_vector_list_arr\n",
    "# del test_label_list_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11660\n",
      "11660\n",
      "512\n",
      "11660\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "#this list have document vectors,every vector,every document have 512 token vectors and every oken vector have 3072 entries\n",
    "print(len(doc_vectors_list_arr))\n",
    "print(len(doc_label_list_arr))\n",
    "print(len(doc_vectors_list_arr[1]))\n",
    "print(len(doc_label_list_arr))\n",
    "print(len(doc_vectors_list_arr[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10494\n",
      "1166\n"
     ]
    }
   ],
   "source": [
    "#splitiing the data into train and validation\n",
    "x_t, x_v, y_t, y_v = train_test_split(doc_vectors_list_arr, doc_label_list_arr, test_size=0.1,random_state=42,stratify=doc_label_list_arr)\n",
    "print(len(x_t))\n",
    "print(len(x_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10494\n",
      "10494\n",
      "1166\n",
      "1166\n",
      "1670\n",
      "1670\n"
     ]
    }
   ],
   "source": [
    "#converting features into numpy array\n",
    "x_train=[]\n",
    "y_train=[]\n",
    "x_val=[]\n",
    "y_val=[]\n",
    "x_test=[]\n",
    "y_test=[]\n",
    "\n",
    "#train set\n",
    "for ent in x_t:\n",
    "    x_train.append(np.array(ent,dtype=np.float32))\n",
    "\n",
    "for ent in y_t:\n",
    "    y_train.append(np.array(ent,dtype=np.int32))\n",
    "\n",
    "#validation set\n",
    "for ent in x_v:\n",
    "    x_val.append(np.array(ent,dtype=np.float32))\n",
    "\n",
    "for ent in y_v:\n",
    "     y_val.append(np.array(ent,dtype=np.int32))\n",
    "\n",
    "#test set\n",
    "for ent in test_vector_list_arr:\n",
    "    x_test.append(np.array(ent,dtype=np.float32))\n",
    "\n",
    "for ent in test_label_list_arr:\n",
    "    y_test.append(np.array(ent,dtype=np.int32))\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "print(len(x_val))\n",
    "print(len(y_val))\n",
    "print(len(x_test))\n",
    "print(len(y_test))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del x_train\n",
    "# del y_train\n",
    "# del x_val\n",
    "# del y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    Source: https://www.cs.cmu.edu/~hovy/papers/16HLT-hierarchical-attention-networks.pdf\n",
    "            https://humboldt-wi.github.io/blog/research/information_systems_1819/group5_han/\n",
    "   \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self,attention_dim=768,return_coefficients=False,**kwargs):\n",
    "        # Initializer \n",
    "        self.supports_masking = True\n",
    "        self.return_coefficients = return_coefficients\n",
    "        self.init = initializers.get('glorot_uniform') # initializes values with uniform distribution\n",
    "        self.attention_dim = attention_dim\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # print(input_shape[0])\n",
    "        # print(input_shape[-1])\n",
    "        # print(input_shape[1])\n",
    "        # Builds all weights\n",
    "        # W = Weight matrix, b = bias vector, u = context vector\n",
    "        assert len(input_shape) == 3\n",
    "        self.W = K.variable(self.init((int(input_shape[-1]), self.attention_dim)),name='W')\n",
    "        self.b = K.variable(self.init((self.attention_dim, )),name='b')\n",
    "        self.u = K.variable(self.init((self.attention_dim, 1)),name='u')\n",
    "        self._trainable_weights = [self.W, self.b, self.u]\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, hit, mask=None):\n",
    "        # Here, the actual calculation is done\n",
    "        uit = K.bias_add(K.dot(hit, self.W),self.b)\n",
    "        uit = K.tanh(uit)\n",
    "        \n",
    "        ait = K.dot(uit, self.u)\n",
    "        ait = K.squeeze(ait, -1)\n",
    "        ait = K.exp(ait)\n",
    "        \n",
    "        if mask is not None:\n",
    "            ait *= K.cast(mask, K.floatx())\n",
    "\n",
    "        ait /= K.cast(K.sum(ait, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        ait = K.expand_dims(ait)\n",
    "        weighted_input = hit * ait\n",
    "        \n",
    "        if self.return_coefficients:\n",
    "            return [K.sum(weighted_input, axis=1), ait]\n",
    "        else:\n",
    "            return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.return_coefficients:\n",
    "            return [(input_shape[0], int(input_shape[-1])), (input_shape[0], int(input_shape[-1]), 1)]\n",
    "        else:\n",
    "            return input_shape[0], int(input_shape[-1])\n",
    "\n",
    "    # def get_config(self):\n",
    "\n",
    "    #     config = super().get_config().copy()\n",
    "    #     config.update({\n",
    "    #         'attention_dim ': self.attention_dim ,\n",
    "    #         'return_coefficients': self.return_coefficients,\n",
    "    #     })\n",
    "    #     return config\n",
    "\n",
    "    def get_config(self):#to avoiding saving problem.check(https://stackoverflow.com/questions/50837728/valueerror-unknown-layer-capsulelayer and    \n",
    "        #https://stackoverflow.com/questions/58678836/notimplementederror-layers-with-arguments-in-init-must-override-get-conf)\n",
    "        # For serialization with 'custom_objects'\n",
    "        config = super().get_config()\n",
    "        config['attention_dim'] = self.attention_dim\n",
    "        config['return_coefficients'] = self.return_coefficients\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "# embedding_matrix = np.random.random((VOCAB_SIZE, EMBEDDING_DIM))\n",
    "# max_sentenses=1\n",
    "# embedding_layer = Embedding(VOCAB_SIZE,EMBEDDING_DIM,input_length=MAX_SEQUENCE_LENGTH,trainable=False,weights=[embedding_matrix],name='word_embedding')\n",
    "MAX_SEQUENCE_LENGTH=512\n",
    "EMBEDDING_DIM=768\n",
    "max_sentenses=1\n",
    "\n",
    "# Words  attention\n",
    "emb_input = Input(shape=(MAX_SEQUENCE_LENGTH,EMBEDDING_DIM), dtype='float32',name='embeddings_input')\n",
    "# #word_sequences = embedding_layer(word_input)\n",
    "gru_word = Bidirectional(GRU(768, return_sequences=True),name='word_GRU')(emb_input)#by default if we set treturn_sequence=False it will\n",
    "#return only last words hidden state is returm only as the output having vector dimensions=2*GRU units \n",
    "#for bidirectional\n",
    "# word_dense = Dense(1536, activation='relu', name='word_dense')(gru_out) \n",
    "word_attention,word_coff= AttentionLayer(EMBEDDING_DIM,return_coefficients=True,name='word_attention')(gru_word)\n",
    "\n",
    "# dense_out = Dense(512,activation='relu', name='word_dense')(word_attention)#we may use different number of units\n",
    "# preds = Dense(13, activation='softmax',name='output')(dense_out)\n",
    "# model = Model(emb_input, preds)\n",
    "WordEnc = Model(inputs = emb_input,outputs = word_attention)#word encoder\n",
    "\n",
    "\n",
    "\n",
    "#Sentence Attention\n",
    "sentence_inp=Input(shape=(max_sentenses, MAX_SEQUENCE_LENGTH,EMBEDDING_DIM), dtype='float32')\n",
    "sent_encoder = TimeDistributed(WordEnc,name='sent_encd')(sentence_inp)\n",
    "gru_sentense = Bidirectional(GRU(100, return_sequences=True),name='sentense_GRU')(sent_encoder)\n",
    "sentense_attention,sentense_coff= AttentionLayer(EMBEDDING_DIM,True,name='sentense_attention')(gru_sentense)\n",
    "dense_out = Dense(512,activation='relu', name='sentense_dense')(sentense_attention)#we may use different number of units\n",
    "dropout = Dropout(0.4,name='dropout')(dense_out)\n",
    "preds = Dense(13, activation='softmax',name='output')(dropout)\n",
    "model = Model(sentence_inp, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embeddings_input (InputLaye  [(None, 512, 768)]       0         \n",
      " r)                                                              \n",
      "                                                                 \n",
      " word_GRU (Bidirectional)    (None, 512, 1536)         7087104   \n",
      "                                                                 \n",
      " word_attention (AttentionLa  [(None, 1536),           1181184   \n",
      " yer)                         (None, 512, 1)]                    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,268,288\n",
      "Trainable params: 8,268,288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1, 512, 768)]     0         \n",
      "                                                                 \n",
      " sent_encd (TimeDistributed)  (None, 1, 1536)          8268288   \n",
      "                                                                 \n",
      " sentense_GRU (Bidirectional  (None, 1, 200)           982800    \n",
      " )                                                               \n",
      "                                                                 \n",
      " sentense_attention (Attenti  [(None, 200),            155136    \n",
      " onLayer)                     (None, 1, 1)]                      \n",
      "                                                                 \n",
      " sentense_dense (Dense)      (None, 512)               102912    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 13)                6669      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,515,805\n",
      "Trainable params: 9,515,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "print(WordEnc.summary())\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1670, 512, 768)\n",
      "(1670,)\n",
      "(1670, 1, 512, 768)\n"
     ]
    }
   ],
   "source": [
    "#Adding dimension into training and test data and converting into numpy array\n",
    "# x_tr = np.array([x_train])\n",
    "# y_tr = np.array(y_train)\n",
    "x_ts=np.array([x_test])\n",
    "y_ts=np.array(y_test)\n",
    "#Reshaping inputs\n",
    "# print(x_tr.shape)\n",
    "# print(y_tr.shape)\n",
    "print(x_ts.shape)\n",
    "print(y_ts.shape)\n",
    "# x_trn=np.transpose(x_tr, (1, 0, 2,3))\n",
    "x_tst=np.transpose(x_ts, (1, 0, 2,3))\n",
    "# print(x_trn.shape)\n",
    "print(x_tst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import math\n",
    "class DataGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, x_train, y_train,batch_size):\n",
    "        self.x, self.y = x_train, y_train\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)#ValueError: axes don't match array\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        x_tr = np.array([self.x[idx * self.batch_size:(idx + 1) *\n",
    "        self.batch_size]])#we also added an extra dimension according to our requirement\n",
    "        y_tr = np.array(self.y[idx * self.batch_size:(idx + 1) *\n",
    "        self.batch_size])\n",
    "\n",
    "        x_trn=np.transpose(x_tr, (1, 0, 2,3))#reshape the input\n",
    "\n",
    "        return x_trn,y_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator=DataGenerator(x_train, y_train,32)\n",
    "val_generator=DataGenerator(x_val, y_val,32)\n",
    "#test_generator = DataGenerator(x_test,y_test,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: dict_keys([4, 3, 2, 12, 7, 8, 1, 5, 11, 0, 9, 6, 10])\n",
      "samples in each label: dict_values([491, 1542, 1438, 1312, 780, 982, 1045, 969, 2363, 588, 72, 23, 55])\n"
     ]
    }
   ],
   "source": [
    "#checking the total samples in each class(label)\n",
    "from collections import Counter\n",
    "print(f\"labels: {Counter(doc_label_list_arr).keys()}\")\n",
    "print(f\"samples in each label: {Counter(doc_label_list_arr).values()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max samples in class ( Referral Letter=2363)\n",
      "***********\n",
      "class weights: {'Admin Note': 4.02, 'Clinical History And Summary': 2.26, 'Consult Note': 1.64, 'Cover Page': 1.53, 'Imaging Note': 4.81, 'Insurance Authorization': 2.44, 'Intake Forms': 102.74, 'Lab Test': 3.03, 'Other': 2.41, 'Patient Profile': 32.82, 'Prescriptions': 42.96, 'Referral Letter': 1.0, 'Requisition Form': 1.8}\n",
      "********\n",
      "class weights: {0: 4.02, 1: 2.26, 2: 1.64, 3: 1.53, 4: 4.81, 5: 2.44, 6: 102.74, 7: 3.03, 8: 2.41, 9: 32.82, 10: 42.96, 11: 1.0, 12: 1.8}\n"
     ]
    }
   ],
   "source": [
    "#making class weights dictionary (our classes are imbalance)\n",
    "#getting class having maximum samples\n",
    "class_samples={}\n",
    "train_text='/media/umar_visionx/Backup Plus/Active/Faizan/textrect_dataset'\n",
    "for folder in os.listdir(train_text):\n",
    "    folder_path=os.path.join(train_text,folder)\n",
    "    class_samples[folder]=len(os.listdir(folder_path))\n",
    "print(f'max samples in class ( {max(class_samples, key=class_samples.get)}={class_samples[max(class_samples, key=class_samples.get)]})')\n",
    "max_samples=int(class_samples[max(class_samples, key=class_samples.get)])\n",
    "print('***********')\n",
    "#getting class weights\n",
    "weights={}\n",
    "for folder in os.listdir(train_text):\n",
    "    folder_path=os.path.join(train_text,folder)\n",
    "    weights[folder]=round(max_samples/int(len(os.listdir(folder_path))),2)\n",
    "print(f'class weights: {weights}')\n",
    "print(\"********\")\n",
    "#changing the names of keys in class weight dictionary\n",
    "class_weight={}\n",
    "for (keys1,values1),(keys2,values2) in zip(weights.items(),label_index.items()):\n",
    "\n",
    "    class_weight[int(values2)]=values1\n",
    "\n",
    "print(f'class weights: {class_weight}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 [==============================] - 1516s 5s/step - loss: 1.1513 - acc: 0.9009 - val_loss: 0.2313 - val_acc: 0.9245\n",
      "328/328 [==============================] - 1510s 5s/step - loss: 0.8434 - acc: 0.9093 - val_loss: 0.2739 - val_acc: 0.9048\n",
      "328/328 [==============================] - 1514s 5s/step - loss: 1.0127 - acc: 0.9052 - val_loss: 0.4265 - val_acc: 0.8533\n",
      " 94/328 [=======>......................] - ETA: 17:22 - loss: 0.6597 - acc: 0.9013"
     ]
    }
   ],
   "source": [
    "\n",
    "#generator=training_generator\n",
    "#from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#batch_size = 32\n",
    "checkpoint_path='/media/umar_visionx/Backup Plus/Active/Faizan/weighted_textrect_model/'#/my_model.h5\n",
    "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)#early stopping\n",
    "#mc = ModelCheckpoint(checkpoint_path, monitor='val_acc', mode='max', verbose=1, save_best_only=True)#model checkpoint\n",
    "loss_list=[]\n",
    "#loss_list.append(history.history['val_loss'][0])\n",
    "history=model.fit(train_generator,validation_data=val_generator, epochs=1,class_weight=class_weight,shuffle=True)\n",
    "loss_list.append(history.history['val_loss'][0])\n",
    "for i in range(9):\n",
    "    history=model.fit(train_generator,validation_data=val_generator, epochs=1,class_weight=class_weight,shuffle=True)\n",
    "    loss=history.history['val_loss'][0]\n",
    "    if loss<loss_list[-1]:\n",
    "        #saving the model\n",
    "        model.save(checkpoint_path)\n",
    "        loss_list.append(history.history['val_loss'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 12:05:06.468034: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-05 12:05:06.468175: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-04-05 12:05:06.468268: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-04-05 12:05:06.468359: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-04-05 12:05:06.468446: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-04-05 12:05:06.468531: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-04-05 12:05:06.468616: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-04-05 12:05:06.484799: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-04-05 12:05:06.501103: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-05 12:05:09.387980: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'while' has 11 outputs but the _output_shapes attribute specifies shapes for 37 outputs. Output shapes may be inaccurate.\n",
      "2022-04-05 12:05:09.977492: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'while' has 11 outputs but the _output_shapes attribute specifies shapes for 37 outputs. Output shapes may be inaccurate.\n",
      "2022-04-05 12:05:09.989586: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'model/word_GRU/forward_gru/PartitionedCall' has 4 outputs but the _output_shapes attribute specifies shapes for 41 outputs. Output shapes may be inaccurate.\n",
      "2022-04-05 12:05:09.989818: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'model/word_GRU/backward_gru/PartitionedCall' has 4 outputs but the _output_shapes attribute specifies shapes for 42 outputs. Output shapes may be inaccurate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1, 512, 768)]     0         \n",
      "                                                                 \n",
      " sent_encd (TimeDistributed)  (None, 1, 1536)          8268288   \n",
      "                                                                 \n",
      " sentense_GRU (Bidirectional  (None, 1, 200)           982800    \n",
      " )                                                               \n",
      "                                                                 \n",
      " sentense_attention (Attenti  [(None, 200),            155136    \n",
      " onLayer)                     (None, 1, 1)]                      \n",
      "                                                                 \n",
      " sentense_dense (Dense)      (None, 512)               102912    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 13)                6669      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,515,805\n",
      "Trainable params: 9,515,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path='/media/umar_visionx/Backup Plus/Active/Faizan/weighted_textrect_model/'#/my_model.h5\n",
    "model = tf.keras.models.load_model('/media/umar_visionx/Backup Plus/Active/Faizan/model_keras/')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.14990822970867157],\n",
       " 'acc': [0.9527348875999451],\n",
       " 'val_loss': [0.24877971410751343],\n",
       " 'val_acc': [0.9288164377212524]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 11:57:52.176247: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2626682880 exceeds 10% of free system memory.\n",
      "2022-04-03 11:57:57.871257: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 50331648 exceeds 10% of free system memory.\n",
      "2022-04-03 11:57:57.871363: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 50331648 exceeds 10% of free system memory.\n",
      "2022-04-03 11:57:57.871482: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 50331648 exceeds 10% of free system memory.\n",
      "2022-04-03 11:57:57.871693: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 50331648 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 81s 1s/step - loss: 1.4804 - acc: 0.7204\n",
      "Test loss: 1.4804365634918213\n",
      "Test accuracy: 0.7203592658042908\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_tst, y_ts, verbose = 1) \n",
    "\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0 ... 12 12 12]\n"
     ]
    }
   ],
   "source": [
    "predictions=model.predict(x_tst)\n",
    "pred = np.argmax(predictions, axis = 1)\n",
    "print(pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.64      0.71        76\n",
      "           1       0.68      0.72      0.70       336\n",
      "           2       0.67      0.77      0.72       349\n",
      "           3       0.93      0.96      0.95       172\n",
      "           4       0.65      0.82      0.73        45\n",
      "           5       0.47      0.26      0.33        31\n",
      "           6       0.00      0.00      0.00         8\n",
      "           7       0.75      0.89      0.82       130\n",
      "           8       0.75      0.34      0.46       247\n",
      "           9       0.73      0.66      0.69        41\n",
      "          10       0.40      0.25      0.31         8\n",
      "          11       0.63      0.95      0.75       154\n",
      "          12       1.00      0.84      0.91        73\n",
      "\n",
      "    accuracy                           0.72      1670\n",
      "   macro avg       0.65      0.62      0.62      1670\n",
      "weighted avg       0.73      0.72      0.71      1670\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umar_visionx/anaconda3/envs/lmv2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/umar_visionx/anaconda3/envs/lmv2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/umar_visionx/anaconda3/envs/lmv2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_ts,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7203592814371258\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_tst' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_247403/2739842058.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#feature extraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_ts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_tst' is not defined"
     ]
    }
   ],
   "source": [
    "#feature extraction\n",
    "predictions=model.predict(x_tst)\n",
    "labels=y_ts\n",
    "print(preictions[1].shape)\n",
    "print(labels[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "229bb8c562dc6514b703716efac498ecdfe3964b4336041201b73c82b78cece5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
