{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch\n",
    "# !pip install transformers\n",
    "#! sudo apt install tesseract-ocr\n",
    "#! pip install pytesseract\n",
    "#! pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix,ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "# tqdm.tqdm(dirs, desc='dirs') \n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "#import itertools\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer #tokanization and removel of punctuation \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Admin Note', 'Clinical History And Summary', 'Consult Note', 'Cover Page', 'Imaging Note', 'Insurance Authorization', 'Intake Forms', 'Lab Test', 'Other', 'Patient Profile', 'Prescriptions', 'Referral Letter', 'Requisition Form']\n"
     ]
    }
   ],
   "source": [
    "#classes\n",
    "txt_path='/media/umar_visionx/Backup Plus/Active/Faizan/doc_classifier_classes.txt'\n",
    "with open(txt_path,'r') as file:\n",
    "    classes=file.read().split('\\n')\n",
    "print(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #to extract text from the document we are applying OCR to each document\n",
    "# def apply_ocr(sample):\n",
    "\n",
    "#         # apply ocr to the image\n",
    "#         #Extracting words and bounding boxes from images\n",
    "#         ocr_dframe = pytesseract.image_to_data(sample, output_type='data.frame')\n",
    "#         #return a subset of the DataFrame's columns based on the column dtypes.\n",
    "#         float_cols = ocr_dframe.select_dtypes('float').columns\n",
    "#         #dropping the rows where atleast one element is not present(i.e \"text\" is not present)\n",
    "#         ocr_dframe = ocr_dframe.dropna().reset_index(drop=True)\n",
    "#         #selecting float_cols,round along zero,changing type to integer\n",
    "#         ocr_dframe[float_cols] = ocr_dframe[float_cols].round(0).astype(int)\n",
    "#         #replace field that's entirely space (or empty) with NaN check https://stackoverflow.com/questions/13445241/replacing-blank-values-white-space-with-nan-in-pandas\n",
    "#         ocr_dframe = ocr_dframe.replace(r'^\\s*$', np.nan, regex=True)\n",
    "#         #dropping the rows where atleast one element is not present(i.e \"text\" is not present)\n",
    "#         ocr_dframe = ocr_dframe.dropna().reset_index(drop=True)\n",
    "\n",
    "#         # get the words and actual (unnormalized) bounding boxes\n",
    "#         #words = [word for word in ocr_dframe.text if str(word) != 'nan'])\n",
    "#         words = list(ocr_dframe.text)#making the list of column \"text\" in 'ocr_dframe' dataframe\n",
    "#         #words = [str(w) for w in words] #converting into list of string of words from the last words list \n",
    "\n",
    "#         #making a list of words in the image\n",
    "#         image_words=[]\n",
    "#         for word in words:\n",
    "#           if str(word)!=\"nan\":\n",
    "#             image_words.append(str(word))\n",
    "\n",
    "      \n",
    "#         #joining words with space\n",
    "#         words= \" \".join(image_words)\n",
    "#         return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #making folders and saving the text files (with extracted text from image) in related folders\n",
    "# def extract_text(source_path,dest_path):\n",
    "#     #first making folders\n",
    "#     try:\n",
    "#         os.makedirs(dest_path)\n",
    "#         for ent in classes:\n",
    "#             folder_path=os.path.join(dest_path,ent)\n",
    "#             os.makedirs(folder_path)\n",
    "#             print(\"Folder making process completed\")\n",
    "#     except:\n",
    "#         pass\n",
    "#     for folder in os.listdir(source_path):\n",
    "#         folder_path=os.path.join(source_path,folder)\n",
    "#         for files in os.listdir(folder_path):\n",
    "#             f_path=os.path.join(folder_path,files)#path of image\n",
    "#             image = Image.open(f_path)\n",
    "#             image = image.convert(\"RGB\")\n",
    "#             para=apply_ocr(image) #getting words from image\n",
    "        \n",
    "#         #making directory to save the files with same file and folder name\n",
    "#             txt_file=os.path.splitext(files)[0] + \".txt\" #making same name of file as image\n",
    "#             txt_path=os.path.join(dest_path,os.path.join(folder,txt_file))\n",
    "#         #writing and saving file\n",
    "#             with open(txt_path, \"w\") as file:\n",
    "#                 file.write(para)\n",
    "#     print(\"All text files are created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #extracting text from images and creating text files \n",
    "# image_data_source=\"/media/umar_visionx/Backup Plus/Active/Faizan/image_data\"#image data source path\n",
    "# test_image_source=\"/media/umar_visionx/Backup Plus/Active/Faizan/test_images\"#test image data source path\n",
    "# text_dest=\"/media/umar_visionx/Backup Plus/Active/Faizan/dataset\"#extracted text files destinatio path for image data\n",
    "# test_text_dest=\"/media/umar_visionx/Backup Plus/Active/Faizan/test_dataset\"#extracted text files destination path from test image data\n",
    "\n",
    "# extract_text(image_data_source,text_dest)\n",
    "# extract_text(test_image_source,test_text_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing special character and numbers\n",
    "def rem_sp_char(words):\n",
    "    pattern = r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]'  # defined pattern to keep\n",
    "    words=re.sub(pattern, '', words)\n",
    "    return words\n",
    "\n",
    "#tokanizing and removing punctuations\n",
    "def remove_punct(words):\n",
    "  tokenizer = RegexpTokenizer(r'\\w+')\n",
    "  tokens=tokenizer.tokenize(words)\n",
    "  return tokens\n",
    "\n",
    "#lemmitization\n",
    "def lemmitizar(words):\n",
    "  lemmatized_words=[]\n",
    "  l = WordNetLemmatizer()\n",
    "  for word in words:\n",
    "      token = l.lemmatize(word)\n",
    "      lemmatized_words.append(token)\n",
    "  return lemmatized_words\n",
    "\n",
    "#removing stop-words\n",
    "def remove_stopwords(words):\n",
    "  filter_words = []\n",
    "  Stopwords = stopwords.words('english')\n",
    "  for word in words:\n",
    "      if word not in Stopwords:\n",
    "          filter_words.append(word)\n",
    "  return filter_words\n",
    "\n",
    "#converting to lowercase\n",
    "def lower_case(words):\n",
    "  lower_words=[]\n",
    "  for word in words:\n",
    "    lower_words.append(word.lower())\n",
    "  return lower_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path of text files\n",
    "data_path='/media/umar_visionx/Backup Plus/Active/Faizan/dataset'\n",
    "test_path='/media/umar_visionx/Backup Plus/Active/Faizan/test_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Admin Note': 0,\n",
       " 'Clinical History And Summary': 1,\n",
       " 'Consult Note': 2,\n",
       " 'Cover Page': 3,\n",
       " 'Imaging Note': 4,\n",
       " 'Insurance Authorization': 5,\n",
       " 'Intake Forms': 6,\n",
       " 'Lab Test': 7,\n",
       " 'Other': 8,\n",
       " 'Patient Profile': 9,\n",
       " 'Prescriptions': 10,\n",
       " 'Referral Letter': 11,\n",
       " 'Requisition Form': 12}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label encoding\n",
    "labl=[]\n",
    "for folder in os.listdir(data_path):\n",
    "  labl.append(folder)#making the list of folder names which are labels\n",
    "\n",
    "\n",
    "#encoding the labels from the list\n",
    "label_index={}\n",
    "for index,label in enumerate(labl):\n",
    "  label_index[label]=index\n",
    "\n",
    "label_index#label to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Admin Note', 1: 'Clinical History And Summary', 2: 'Consult Note', 3: 'Cover Page', 4: 'Imaging Note', 5: 'Insurance Authorization', 6: 'Intake Forms', 7: 'Lab Test', 8: 'Other', 9: 'Patient Profile', 10: 'Prescriptions', 11: 'Referral Letter', 12: 'Requisition Form'}\n"
     ]
    }
   ],
   "source": [
    "#making dictionary for label decoding\n",
    "index_label={}\n",
    "for key,val in zip(label_index.keys(),label_index.values()):\n",
    "    index_label[val]=key\n",
    "print(index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dictionaries and lists of text and labels\n",
    "def preprocessed_df(data_path):\n",
    "    data_dict={}\n",
    "    #txt_file_path=[]\n",
    "    labels=[]\n",
    "    text=[]\n",
    "    encoded_labels=[]\n",
    "    for clss in os.listdir(data_path):\n",
    "        clss_path=os.path.join(data_path,clss)\n",
    "        for txt_file in os.listdir(clss_path):\n",
    "            file_path=os.path.join(clss_path,txt_file)\n",
    "            #reading text file\n",
    "            with open(file_path, \"r\") as file:\n",
    "                para = file.read().rstrip('\\n')#rstrip method removes trailing character based on string argument passed\n",
    "\n",
    "            #apply preprocessing functions on para\n",
    "                words = rem_sp_char(para) #removing special character and numbers\n",
    "                tokens = remove_punct(words) #removing punctuations and tokanization\n",
    "                tokens = lemmitizar(tokens) #lemmitization\n",
    "                tokens = remove_stopwords(tokens) ##removing stop-words\n",
    "                tokens = lower_case(tokens) #converting to lowercase\n",
    "\n",
    "            #joining words with space and removing single tetter tokens\n",
    "                parag=' '.join( [word for word in tokens if len(word)>1] )\n",
    "            #parag=' '.join( [word for word in tokens if len(word)>1 and word.isalpha()] )#if we dont want numeric values\n",
    "\n",
    "\n",
    "            #inseting data into lists and dictionaries\n",
    "                text.append(parag)\n",
    "            #text_file_path.append(file_path)\n",
    "                labels.append(clss)\n",
    "                data_dict[parag]=clss\n",
    "#label encoding\n",
    "    for ent in labels:\n",
    "        encoded_labels.append(label_index[ent])\n",
    "    \n",
    "\n",
    "\n",
    "    df=pd.DataFrame()\n",
    "    df['text']=text\n",
    "    df['labels']=encoded_labels\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29 2021 10 42 alberta health services rrduser ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30 2021 09 34 alberta health services rrduser ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29 2021 11 03 alberta health services rrduser ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021 08 25 alberta health services rrduser 403...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ahs 2021 23 05 am page alberta health services...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0  29 2021 10 42 alberta health services rrduser ...       0\n",
       "1  30 2021 09 34 alberta health services rrduser ...       0\n",
       "2  29 2021 11 03 alberta health services rrduser ...       0\n",
       "3  2021 08 25 alberta health services rrduser 403...       0\n",
       "4  ahs 2021 23 05 am page alberta health services...       0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=preprocessed_df(data_path)\n",
    "df_test=preprocessed_df(test_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11660\n",
      "1810\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#checking null values in dataframes\n",
    "print(df.isnull().any().sum())\n",
    "print(df_test.isnull().any().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Labels after Encoding:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique Labels after Encoding:  {df.labels.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#BERT base model\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased',output_hidden_states = True,)#model returns all hidden-states.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "train_dataset = Dataset.from_pandas(df)\n",
    "#val_dataset = Dataset.from_pandas(df_val)\n",
    "test_dataset = Dataset.from_pandas(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_example(sample,max_seq_length=512):\n",
    "    words=sample['text']\n",
    "    label=sample['labels']\n",
    "    #splitting all words of sentence in to into tokens\n",
    "    tokenized_text = tokenizer.tokenize(words)\n",
    "    # Truncation of token_boxes\n",
    "    special_tokens_count = 2 \n",
    "    if len(tokenized_text) > max_seq_length - special_tokens_count:\n",
    "      tokenized_text = tokenized_text[: (max_seq_length - special_tokens_count)]#to make place available for cls and sep tokens\n",
    "    # Adding CLS and SEP tokens\n",
    "    input_sequence = [\"[CLS]\"] + tokenized_text + [\"[SEP]\"]\n",
    "    # Map the tokens to their vocabulary indeces\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "    #padding length\n",
    "    padding_length = max_seq_length - len(input_sequence)\n",
    "    indexed_tokens += [0] * padding_length#zero padding to maximum length\n",
    "    #as we are giving as a single sentence so mark each token as belonging to sentence 1\n",
    "    segments_ids = [1] * max_seq_length\n",
    "    pad_masks = [1] * len(input_sequence) + [0] * padding_length\n",
    "\n",
    "\n",
    "    assert len(indexed_tokens) == max_seq_length\n",
    "    assert len(segments_ids) ==max_seq_length\n",
    "    assert len(pad_masks) == max_seq_length\n",
    "\n",
    "    #converting into pytorch tensors\n",
    "    tokens_tensor = torch.tensor(indexed_tokens)\n",
    "    segments_tensors = torch.tensor(segments_ids)\n",
    "    pad_mask_tensors=torch.tensor(pad_masks)\n",
    "    label_tensors=torch.tensor(label)\n",
    "    \n",
    "  \n",
    "    tok_tensors.append(tokens_tensor)\n",
    "    seg_tensors.append(segments_tensors)\n",
    "    lab_tensors.append(label_tensors)\n",
    "    pad_msk_tensors.append(pad_mask_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_df(dataset):\n",
    "    global tok_tensors,seg_tensors,lab_tensors,pad_msk_tensors\n",
    "\n",
    "    tok_tensors=[]\n",
    "    seg_tensors=[]\n",
    "    lab_tensors=[]\n",
    "    pad_msk_tensors=[]\n",
    "    dataset.map(encode_example)\n",
    "    # df=pd.DataFrame()\n",
    "    # df['token_tensors']=tok_tensors\n",
    "    # df['segment_tensor']=seg_tensors\n",
    "    # df['labels']=lab_tensors\n",
    "    return tok_tensors,seg_tensors,lab_tensors,pad_msk_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12accfcf5f524c408d39e4ffde7a52e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11660 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40bf9dbe444647f9986dab43ed6220b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1810 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_token_tensor,tr_segment_tensors,tr_label_tensors,tr_pad_msk_tensors=iter_df(train_dataset)\n",
    "ts_token_tensor,ts_segment_tensors,ts_label_tensorsts,ts_pad_msk_tensors=iter_df(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset\n",
    "class PhelixDataset(Dataset):\n",
    "    def __init__(self, token_tens,label_tens,seg_tens,pd_msk_tens):\n",
    "        #super().__init__()\n",
    "        self.token_tens = token_tens\n",
    "        self.seg_tens=seg_tens\n",
    "        self.label_tens=label_tens\n",
    "        self.pd_msk_tens=pd_msk_tens\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_tens)\n",
    "    \n",
    "    def __getitem__(self, index):       \n",
    "        tokens_id = self.token_tens[index]\n",
    "        segment_id = self.seg_tens[index]\n",
    "        label=self.label_tens[index]\n",
    "        pad_mask=self.pd_msk_tens[index]\n",
    "\n",
    "        return tokens_id,label,segment_id,pad_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader,Dataset\n",
    "# class PhelixDataset(Dataset):\n",
    "#     def __init__(self, token_tens,seg_tens):\n",
    "#         #super().__init__()\n",
    "#         self.token_tens = token_tens\n",
    "#         self.seg_tens=seg_tens\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.token_tens)\n",
    "    \n",
    "#     def __getitem__(self, index):       \n",
    "#         tokens_id = self.token_tens[index]\n",
    "#         segment_id = self.seg_tens[index]\n",
    "\n",
    "#         return tokens_id,segment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  101,  2340,  2423, 12609,  2403,  2322, 12458,  2094,  9634,  6904,\n",
      "          2595,  6904,  2015,  6564, 28756, 24594, 21486, 24434,  5776,  2592,\n",
      "         19739, 20486,  4263,  2592,  2171,  2879,  3401,  2798,  2171,  3348,\n",
      "          2128,  2140,  2969,  7020,  2078,  7020,  2078,  2720,  2078,  8732,\n",
      "          2620, 18827,  2575,  4769,  6146, 17788,  4496,  5243,  3367,  2852,\n",
      "          4769,  4769,  4769,  2103,  2358,  4138,  3122,  4564, 19067,  2103,\n",
      "          2358, 14101,  6146, 15136,  2692,  2575, 17914,  2509, 14101,  7026,\n",
      "          6282,  2581,  2575,  2683, 18827, 24096,  2575,  7026,  3058,  4182,\n",
      "          5641,  2403,  3874,  5427,  2592,  1042, 11020,  2171,  8292,  5339,\n",
      "          2053,  2177,  2933,  4942, 29234,  2099,  2128,  2140, 18253,  1051,\n",
      "         27487, 27615, 24528,  2278,  1021,  2546,  2290,  2620, 10374,  2546,\n",
      "          2078, 18827,  2879,  3401,  2798,  7367, 27908,  9779, 14536, 27615,\n",
      "         10514,  9397,  2571, 23980, 26187, 16703, 12376, 12521,  2879,  3401,\n",
      "          2798,  7367,  5776,  8085,  3058,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), tensor([9]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])]\n"
     ]
    }
   ],
   "source": [
    "batch_size=1\n",
    "train_data = PhelixDataset(tr_token_tensor,tr_label_tensors,tr_segment_tensors,tr_pad_msk_tensors)\n",
    "test_data = PhelixDataset(ts_token_tensor,ts_label_tensorsts,ts_segment_tensors,ts_pad_msk_tensors)\n",
    "train_dataloader = DataLoader(train_data, batch_size = batch_size,shuffle=True,num_workers=3,pin_memory=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size = batch_size,shuffle=False,num_workers=3,pin_memory=True)\n",
    "sample = next(iter(train_dataloader))\n",
    "print(sample)\n",
    "# batch=next(iter(train_dataloader))\n",
    "# print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n",
      "torch.Size([1])\n",
      "torch.Size([1, 512])\n",
      "torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "for token, label,seg,pad_mask in train_dataloader:\n",
    "    print(token.shape)\n",
    "    print(label.shape)\n",
    "    print(seg.shape)\n",
    "    print(pad_mask.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar  7 14:51:13 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:65:00.0  On |                  N/A |\n",
      "|  0%   35C    P2    68W / 320W |   3693MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2098      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    0   N/A  N/A      3203      G   /usr/lib/xorg/Xorg                 83MiB |\n",
      "|    0   N/A  N/A      3335      G   ...mviewer/tv_bin/TeamViewer        2MiB |\n",
      "|    0   N/A  N/A      3434      G   /usr/bin/gnome-shell               19MiB |\n",
      "|    0   N/A  N/A      3584      G   /opt/freedownloadmanager/fdm        2MiB |\n",
      "|    0   N/A  N/A    244270      C   ...ionx/anaconda3/bin/python     2261MiB |\n",
      "|    0   N/A  N/A    272731      C   ...ionx/anaconda3/bin/python     1273MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#testing GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(data_loader):\n",
    "  #creating word embeddings\n",
    "  model.eval()\n",
    "  # token_labels_list=[]\n",
    "  # concat_token_vect=[]#define list to append concatinated token vectors\n",
    "  # doc_vectors_list=[]\n",
    "  # doc_label_list=[]\n",
    "  #to save data as arrays \n",
    "  token_labels_list_arr=[]\n",
    "  concat_token_vect_arr=[]\n",
    "  doc_vectors_list_arr=[]\n",
    "  doc_label_list_arr=[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  for tokens,label,seg_id,_ in tqdm(data_loader):\n",
    "  \n",
    "      #moving to device\n",
    "      label=int(label)\n",
    "      tokens=tokens.to(device)\n",
    "      seg_id=seg_id.to(device)\n",
    "      with torch.no_grad():\n",
    "        output = model(tokens,seg_id)\n",
    "      #we set output_hidden_state=True in our pre trained model so, we will get the hidden states from all 13 layers at third positiob\n",
    "      hidden_states = output[2]\n",
    "      #For futher info please check https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/\n",
    "      # Concatenating tensors for all layers and creating new dim with the help of stack\n",
    "      token_embed = torch.stack(hidden_states, dim=0)#token embeddings(torch.Size([13, 1, 512, 768]))\n",
    "      token_embed = torch.squeeze(token_embed, dim=1)#removing batch dimension(torch.Size([13, 512, 768]))\n",
    "      token_embed = token_embed.permute(1,0,2)# swapping dimensions(torch.Size([512, 13, 768]))\n",
    "      #iterating for each token in whole document/sentense\n",
    "      to_append_vect=[]\n",
    "      to_append_vect_arr=[]\n",
    "      #to_append_label=[]\n",
    "      for token in token_embed:\n",
    "          #token vector of size 13*768 where 13 are number of layers while we want to get only last 4 layers i.e 4*768\n",
    "          #after concatination last four layers vector dimensions will be 4*768=3,072(singlre word vector length i.e per token)\n",
    "          #concatinating vectors\n",
    "          add1 = torch.add(token[-1], token[-2])\n",
    "          add2=torch.add(token[-3], token[-4])\n",
    "          full_vector=torch.add(add1,add2)\n",
    "          #concatcat_vector = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "          # concat_token_vect.append(full_vector)\n",
    "          #we have append 512 vectors of size 768 for each document\n",
    "          # token_labels_list.append(label)\n",
    "          token_labels_list_arr.append(label)\n",
    "          concat_token_vect_arr.append(full_vector.cpu().numpy())\n",
    "\n",
    "          to_append_vect_arr.append(full_vector.cpu().numpy())\n",
    "          to_append_vect.append(full_vector)\n",
    "          #to_append_label.append(label)\n",
    "      # print(len(to_append_vect_arr))\n",
    "      # print(len(to_append_vect))\n",
    "\n",
    "\n",
    "      # doc_vectors_list.append(to_append_vect)\n",
    "      # doc_label_list.append(label)\n",
    "      doc_vectors_list_arr.append(to_append_vect_arr)\n",
    "      doc_label_list_arr.append(label)\n",
    "  return doc_vectors_list_arr,doc_label_list_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_vectors_list,train_doc_label_list = embed(train_dataloader)\n",
    "test_doc_vectors_list,test_doc_label_list = embed(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this list have document vectors,every vector,every document have 512 token vectors and every oken vector have 3072 entries\n",
    "print(len(train_doc_vectors_list[0:10]))\n",
    "print(len(train_doc_label_list))\n",
    "print(len(train_doc_vectors_list[1]))\n",
    "print(len(train_doc_label_list))\n",
    "print(len(train_doc_vectors_list[1][1]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "229bb8c562dc6514b703716efac498ecdfe3964b4336041201b73c82b78cece5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
