# Multi-Modal-Document-Image-Classification
In this project textual as well as visual features are used to classify image documents. OCR is implemented to get text data from image documents then BERT model is used for text embedding. After this Hierarchical Attention Network HAN with word and sentence attention along with GRU (Gated Recurrent Unit ) is used to classify documents. Second we have done simple image classification on our documents using only visual features. After training both models individually on training data we checked our models performance on test set. We got vectors from both models, combine them and used this vector to classify our documents.The idea is taken from currently published research paper known as "Efficient multi ti modal Document Image Classifier for Scarce Data" (January,2022) at https://www.mdpi.com/2076-3417/12/3/1457. Pytorch and Keras are the main deep learning frameworks that are used in this project.
